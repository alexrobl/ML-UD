{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia Artificial - Laboratorio 1\n",
    "Alexander Robles Mondragón, Cod. 20181395006 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución\n",
    "Compuerta AND y Compuerta OR de 2 entradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from numpy import array, dot, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test = lambda x: 0 if x < 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar los perceptrones debo definir las ventanas and y or, en este caso la variable training_OR representa la ventana OR y training_AND representa la ventana AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_AND = [\n",
    "    (array([0,0,1]),0),\n",
    "    (array([0,1,1]),0),\n",
    "    (array([1,0,1]),0),\n",
    "    (array([1,1,1]),1),\n",
    "]\n",
    "training_OR = [\n",
    "    (array([0,0,1]),0),\n",
    "    (array([0,1,1]),1),\n",
    "    (array([1,0,1]),1),\n",
    "    (array([1,1,1]),1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47510216, 0.71960051, 0.91265719])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = random.rand(3)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a algunas inicializaciones de variables. La lista de errores solo se usa para almacenar los valores de error para que puedan ser graficados más adelante. Si no quieres hacer un trazado, puedes dejarlo. La variable eta controla la tasa de aprendizaje. Y n especifica el número de iteraciones de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]\n",
    "eta = 0.9\n",
    "n=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventana OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función dot(), representa a la función de activación definida y empazare con la ventana OR de dos entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47510216  0.71960051 -0.08734281]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    x, expected = choice(training_OR)\n",
    "    result = dot (w,x)\n",
    "    error = expected - unit_test(result)\n",
    "    errors.append(error)\n",
    "    w += eta * error * x\n",
    "print (w)\n",
    "print (i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente podemos hacer uso de la impresion de parametros para saber el valor de la función de activación \n",
    "y su correspondiente regla de decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]:-0.08734280519531151 -> 0\n",
      "[0 1]:0.6322577030311856 -> 1\n",
      "[1 0]:0.38775935485889074 -> 1\n",
      "[1 1]:1.1073598630853878 -> 1\n"
     ]
    }
   ],
   "source": [
    "for x, _ in training_data:\n",
    "    result = dot(x,w)\n",
    "    print (\"{}:{} -> {}\".format(x[:2], result, unit_test(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventana AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]\n",
    "eta = 0.9\n",
    "n=100\n",
    "error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47510216  1.61960051 -1.88734281]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    x, expected = choice(training_AND)\n",
    "    result = dot (w,x)\n",
    "    error = expected - unit_test(result)\n",
    "    errors.append(error)\n",
    "    w += eta * error * x\n",
    "print (w)\n",
    "print (i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]:-1.8873428051953116 -> 0\n",
      "[0 1]:-0.2677422969688146 -> 0\n",
      "[1 0]:-1.4122406451411091 -> 0\n",
      "[1 1]:0.2073598630853879 -> 1\n"
     ]
    }
   ],
   "source": [
    "for x, _ in training_data:\n",
    "    result = dot(x,w)\n",
    "    print (\"{}:{} -> {}\".format(x[:2], result, unit_test(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCEPTRON MULTICAPA\n",
    "## Compuerta XOR\n",
    "### El perceptron se puede usar como un clasificador binario basado en un vector de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74795208]\n",
      " [0.8008477 ]\n",
      " [0.8081572 ]\n",
      " [0.84332796]]\n",
      "[[0.00430724]\n",
      " [0.99614063]\n",
      " [0.99533477]\n",
      " [0.00425473]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "\treturn 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "\treturn x*(1.0 - x)\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.l=len(self.inputs)\n",
    "        self.li=len(self.inputs[0])\n",
    "\n",
    "        self.wi=np.random.random((self.li, self.l))\n",
    "        self.wh=np.random.random((self.l, 1))\n",
    "\n",
    "    def think(self, inp):\n",
    "        s1=sigmoid(np.dot(inp, self.wi))\n",
    "        s2=sigmoid(np.dot(s1, self.wh))\n",
    "        return s2\n",
    "\n",
    "    def train(self, inputs,outputs, it):\n",
    "        for i in range(it):\n",
    "            l0=inputs\n",
    "            l1=sigmoid(np.dot(l0, self.wi))\n",
    "            l2=sigmoid(np.dot(l1, self.wh))\n",
    "\n",
    "            l2_err=outputs - l2\n",
    "            l2_delta = np.multiply(l2_err, sigmoid_der(l2))\n",
    "\n",
    "            l1_err=np.dot(l2_delta, self.wh.T)\n",
    "            l1_delta=np.multiply(l1_err, sigmoid_der(l1))\n",
    "\n",
    "            self.wh+=np.dot(l1.T, l2_delta)\n",
    "            self.wi+=np.dot(l0.T, l1_delta)\n",
    "\n",
    "inputs=np.array([[0,0], [0,1], [1,0], [1,1] ])\n",
    "outputs=np.array([ [0], [1],[1],[0] ])\n",
    "\n",
    "n=NN(inputs)\n",
    "print(n.think(inputs))\n",
    "n.train(inputs, outputs, 100000)\n",
    "print(n.think(inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
